wandb:
  project: "q3c"
  entity: "YOUR_WANDB_ENTITY"  
  sweep_id: null  # This will be set dynamically by W&B only if you use a sweep

train:
  environment: Hopper-v4
  save_gif: False
  disable_wandb: False
  use_lr_schedule: True
  lr_scheduler_function: 'delayed_exponential' # linear, exponential, cosine, delayed_exponential, one_cycle_lr
  normalize_q_values: True
  use_knn: True
  use_learnable_smoothing: False
  smoothing_function: null # softplus, sigmoid, or null, only used with use_learnable_smoothing
  smoothing_decay: "exponential" # linear, exponential, or null
  use_separation_loss: True
  num_envs: 4

environment:
  Pendulum-v1:
    n_timesteps: 50000
    policy: 'MlpPolicy'
    gamma: 0.98
    buffer_size: 200000
    batch_size: 64
    learning_starts: 1000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 1e-3
    policy_kwargs: "dict(net_arch=[400, 300])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 3
    k: 3
    separation_loss_function: "repulsion_loss"
    separation_loss_coefficient: 0.01
    smoothing_value: 0.1

  InvertedPendulum-v4:
    n_timesteps: 100000
    policy: 'MlpPolicy'
    gamma: 0.99
    buffer_size: 100000
    batch_size: 256
    learning_starts: 1000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.2
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 1e-3
    policy_kwargs: "dict(net_arch=[400, 300])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 2
    k: 2

  InvertedPendulumBox-v4:
    n_timesteps: 1000000
    policy: 'MlpPolicy'
    gamma: 0.99
    buffer_size: 100000
    batch_size: 256
    learning_starts: 1000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.2
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 1e-3
    policy_kwargs: "dict(net_arch=[400, 300])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 20
    k: 10
    target_policy_noise: 0.2
    separation_loss_function: "repulsion_loss"
    separation_loss_coefficient: 0.01 
    smoothing_value: 0.1
    valid_box_volume_multiplier: 3
    env_kwargs:
      reacher_action_type: 'original'
      reacher_bijective_dims: 5
      validity_type: 'box'
      mujoco_env_box_seed: 123
      max_episode_steps: 1000

  InvertedDoublePendulum-v4:
    n_timesteps: 1000000
    policy: 'MlpPolicy'
    gamma: 0.97
    buffer_size: 1000000
    batch_size: 256
    learning_starts: 10000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.2
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 1e-3
    policy_kwargs: "dict(net_arch=[400, 300])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 20
    k: 10
    separation_loss_function: "repulsion_loss"
    separation_loss_coefficient: 0.01

  InvertedDoublePendulumBox-v4:
    n_timesteps: 1000000
    policy: 'MlpPolicy'
    gamma: 0.97
    buffer_size: 1000000
    batch_size: 256
    learning_starts: 10000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.2
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 1e-3
    policy_kwargs: "dict(net_arch=[400, 300])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 20
    k: 10
    separation_loss_function: "repulsion_loss"
    separation_loss_coefficient: 0.01
    env_kwargs:
      reacher_action_type: 'original'
      reacher_bijective_dims: 5
      validity_type: 'box'
      mujoco_env_box_seed: 123
      max_episode_steps: 1000

  Reacher-v4: 
    n_timesteps: 100000
    policy: 'MlpPolicy'
    gamma: 0.99
    buffer_size: 1000000
    batch_size: 256
    learning_starts: 10000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 1e-3
    policy_kwargs: "dict(net_arch=[400, 300])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 20
    k: 10
    separation_loss_function: "repulsion_loss"
    separation_loss_coefficient: 0.01

  ReacherBox-v4: 
    n_timesteps: 1000000
    policy: 'MlpPolicy'
    gamma: 0.99
    buffer_size: 1000000
    batch_size: 256
    learning_starts: 10000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 1e-3
    policy_kwargs: "dict(net_arch=[400, 300])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 20
    k: 10
    separation_loss_function: "repulsion_loss"
    separation_loss_coefficient: 0.01
    valid_box_volume_multiplier: 1

  MountainCarContinuous-v0:
    n_timesteps: 300000
    policy: 'MlpPolicy'
    gamma: 0.99
    buffer_size: 1000000
    batch_size: 64
    learning_starts: 5000
    tau: 0.01
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 1e-3
    policy_kwargs: "dict(net_arch=[32, 32])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 2
    k: 2

  Hopper-v4:
    n_timesteps: !!float 1e6
    policy: 'MlpPolicy'
    learning_starts: 30000
    noise_type: 'normal'
    noise_std: 0.1
    train_freq: 1
    gradient_steps: 1
    learning_rate: !!float 1e-3
    batch_size: 256
    policy_kwargs: "dict(net_arch=[400, 300])"
    buffer_size: 100000
    gamma: 0.99
    tau: 0.005
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 20
    k: 10
    separation_loss_function: 'min_n_pair_distances'
    separation_loss_coefficient: 0.01
    smoothing_value: 0.01

  HopperBox-v4:
    n_timesteps: !!float 2e6
    policy: 'MlpPolicy'
    learning_starts: 10000
    noise_type: 'normal'
    noise_std: 0.1
    train_freq: 1
    gradient_steps: 1
    learning_rate: !!float 1e-3
    batch_size: 256
    policy_kwargs: "dict(net_arch=[400, 300])"
    buffer_size: 100000
    gamma: 0.99
    tau: 0.005
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 20
    k: 10
    separation_loss_function: 'repulsion_loss'
    separation_loss_coefficient: 0.1
    valid_box_volume_multiplier: 1.25
    smoothing_value: 0.000001
    env_kwargs:
      reacher_action_type: 'original'
      reacher_bijective_dims: 5
      validity_type: 'box'
      mujoco_env_box_seed: 123
      max_episode_steps: 1000

  BipedalWalker-v3:
    n_timesteps: 1000000
    policy: 'MlpPolicy'
    gamma: 0.98
    buffer_size: 200000
    batch_size: 256
    learning_starts: 10000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 3e-4
    policy_kwargs: "dict(net_arch=[400,300])"
    target_update_interval: 1
    max_grad_norm: 1.0
    num_control_points: 20
    k: 10
    separation_loss_function: 'min_n_pair_distances'
    separation_loss_coefficient: 1
    smoothing_value: 0.001

  BipedalWalkerHardcore-v3:
    n_timesteps: 1000000
    policy: 'MlpPolicy'
    gamma: 0.98
    buffer_size: 200000
    batch_size: 256
    learning_starts: 10000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 3e-4
    policy_kwargs: "dict(net_arch=[400,300])"
    target_update_interval: 1
    max_grad_norm: 1.0
    num_control_points: 20
    k: 10
    separation_loss_function: 'min_n_pair_distances'
    separation_loss_coefficient: 1

  Ant-v4:
    n_timesteps: 3000000
    policy: 'MlpPolicy'
    gamma: 0.99
    buffer_size: 500000
    batch_size: 256
    learning_starts: 10000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 5e-4
    policy_kwargs: "dict(net_arch=[400,300])"
    target_update_interval: 4
    max_grad_norm: 5.0
    num_control_points: 30
    k: 15
    separation_loss_function: 'repulsion_loss'
    separation_loss_coefficient: 0.1
    smoothing_value: 0.001

  # Not Tuned
  AntBox-v4:
    n_timesteps: 3000000
    policy: 'MlpPolicy'
    gamma: 0.99
    buffer_size: 500000
    batch_size: 256
    learning_starts: 10000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 5e-4
    policy_kwargs: "dict(net_arch=[400,300])"
    target_update_interval: 4
    max_grad_norm: 5.0
    num_control_points: 30
    k: 15       
    separation_loss_function: 'repulsion_loss'
    separation_loss_coefficient: 0.1
    smoothing_value: 0.001
    valid_box_volume_multiplier: 1
    env_kwargs:
      reacher_action_type: 'original'
      reacher_bijective_dims: 5
      validity_type: 'box'
      mujoco_env_box_seed: 123
      max_episode_steps: 1000

  HalfCheetah-v4:
    n_timesteps: 1000000
    policy: 'MlpPolicy'
    gamma: 0.99
    buffer_size: 1000000
    batch_size: 256
    learning_starts: 30000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 1e-3
    policy_kwargs: "dict(net_arch=[400, 300])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 20
    k: 10
    separation_loss_function: 'repulsion_loss'
    separation_loss_coefficient: 1
    smoothing_value: 0.01

  HalfCheetahBox-v4:
    n_timesteps: 3000000
    policy: 'MlpPolicy'
    gamma: 0.99
    buffer_size: 100000
    batch_size: 256
    learning_starts: 30000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 3e-4
    policy_kwargs: "dict(net_arch=[400, 300])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 30
    k: 10
    separation_loss_function: "repulsion_loss"
    separation_loss_coefficient: 1
    valid_box_volume_multiplier: 0.25
    smoothing_value: 0.000001
    env_kwargs:
      reacher_action_type: 'original'
      reacher_bijective_dims: 5
      validity_type: 'box'
      mujoco_env_box_seed: 123
      max_episode_steps: 1000

  Swimmer-v4:
    n_timesteps: 1000000
    policy: 'MlpPolicy'
    gamma: 0.9999
    buffer_size: 50000
    batch_size: 256
    learning_starts: 10000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 1e-3
    policy_kwargs: "dict(net_arch=[400, 300])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 20
    k: 10
    separation_loss_function: 'repulsion_loss'
    separation_loss_coefficient: 1
    smoothing_value: 0.1

  # Not Tuned
  SwimmerBox-v4:
    n_timesteps: 1000000
    policy: 'MlpPolicy'
    gamma: 0.9999
    buffer_size: 50000
    batch_size: 256
    learning_starts: 10000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 1e-3
    policy_kwargs: "dict(net_arch=[400, 300])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 20
    k: 10
    separation_loss_function: 'repulsion_loss'
    separation_loss_coefficient: 1
    smoothing_value: 0.1
    valid_box_volume_multiplier: 1
    env_kwargs:
      reacher_action_type: 'original'
      reacher_bijective_dims: 5
      validity_type: 'box'
      mujoco_env_box_seed: 123
      max_episode_steps: 1000

  Walker2d-v4:
    n_timesteps: 1000000
    policy: 'MlpPolicy'
    gamma: 0.99
    buffer_size: 100000
    batch_size: 256
    learning_starts: 10000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 1e-3
    policy_kwargs: "dict(net_arch=[400, 300])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 20
    k: 10
    separation_loss_function: 'repulsion_loss'
    separation_loss_coefficient: 0.1
    smoothing_value: 1

  # Not Tuned
  Walker2dBox-v4:
    n_timesteps: 3000000
    policy: 'MlpPolicy'
    gamma: 0.99
    buffer_size: 100000
    batch_size: 256
    learning_starts: 10000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 1e-3
    policy_kwargs: "dict(net_arch=[400, 300])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 20
    k: 10
    separation_loss_function: "repulsion_loss"
    separation_loss_coefficient: 0.1
    valid_box_volume_multiplier: 0.25
    smoothing_value: 0.1
    env_kwargs:
      reacher_action_type: 'original'
      reacher_bijective_dims: 5
      validity_type: 'box'
      mujoco_env_box_seed: 123
      max_episode_steps: 1000

  # Not Tuned
  AdroitHandDoor-v1:
    n_timesteps: !!float 3e6
    policy: 'MlpPolicy'
    gamma: 0.98
    buffer_size: 500000
    batch_size: 256
    learning_starts: 50000
    tau: 0.01
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 4
    train_freq: 1
    learning_rate: !!float 3e-4
    policy_kwargs: "dict(net_arch=[256,256])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 20
    k: 10
    separation_loss_function: 'repulsion_loss'
    separation_loss_coefficient: 0.1
    smoothing_value: 0.1

  # Not Tuned
  AdroitHandHammer-v1:
    n_timesteps: !!float 5e6
    policy: 'MlpPolicy'
    gamma: 0.98
    buffer_size: 1000000
    batch_size: 256
    learning_starts: 50000
    tau: 0.005
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 1
    train_freq: 1
    learning_rate: !!float 3e-4
    policy_kwargs: "dict(net_arch=[256,256])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 40
    k: 20
    separation_loss_function: 'repulsion_loss'
    separation_loss_coefficient: 0.1
    smoothing_value: 0.1

  # Not Tuned
  AdroitHandPen-v1:
    n_timesteps: !!float 1e6
    policy: 'MlpPolicy'
    gamma: 0.98
    buffer_size: 500000
    batch_size: 256
    learning_starts: 50000
    tau: 0.01
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 4
    train_freq: 1
    learning_rate: !!float 3e-4
    policy_kwargs: "dict(net_arch=[256,256])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 20
    k: 10
    separation_loss_function: 'repulsion_loss'
    separation_loss_coefficient: 0.1
    smoothing_value: 0.1

  # Not Tuned
  AdroitHandRelocate-v1:
    n_timesteps: !!float 1e6
    policy: 'MlpPolicy'
    gamma: 0.98
    buffer_size: 500000
    batch_size: 256
    learning_starts: 50000
    tau: 0.01
    noise_type: 'normal'
    noise_std: 0.1
    gradient_steps: 4
    train_freq: 1
    learning_rate: !!float 3e-4
    policy_kwargs: "dict(net_arch=[256,256])"
    target_update_interval: 4
    max_grad_norm: 10.0
    num_control_points: 20
    k: 10
    separation_loss_function: 'repulsion_loss'
    separation_loss_coefficient: 0.1
    smoothing_value: 0.1